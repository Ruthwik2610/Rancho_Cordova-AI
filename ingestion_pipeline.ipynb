{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa0dde",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell_1_setup.py\n",
    "!pip install -q pinecone-client sentence-transformers langchain-community langchain-text-splitters pypdf pandas tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import PyPDFLoader, DataFrameLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "\n",
    "# --- CONFIGURATION (Enter these temporarily in Colab) ---\n",
    "PINECONE_API_KEY = \"YOUR_PINECONE_API_KEY\"\n",
    "PINECONE_INDEX_NAME = \"rancho-cordova\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "if PINECONE_INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=PINECONE_INDEX_NAME,\n",
    "        dimension=384, \n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2', device=DEVICE)\n",
    "\n",
    "def process_files(file_list):\n",
    "    batch_size = 100\n",
    "    vectors = []\n",
    "    print(f\"üìÇ Processing {len(file_list)} files on {DEVICE}...\")\n",
    "\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            print(f\"   ‚ûú Reading: {file_path}\")\n",
    "            chunks = []\n",
    "            \n",
    "            if file_path.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                pages = loader.load()\n",
    "                splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "                chunks = splitter.split_documents(pages)\n",
    "                \n",
    "            elif file_path.endswith('.csv'):\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['text_context'] = df.apply(lambda x: \" | \".join(x.dropna().astype(str)), axis=1)\n",
    "                loader = DataFrameLoader(df, page_content_column=\"text_context\")\n",
    "                chunks = loader.load()\n",
    "\n",
    "            for idx, chunk in enumerate(chunks):\n",
    "                vector = embed_model.encode(chunk.page_content).tolist()\n",
    "                doc_id = f\"{os.path.basename(file_path)}_{idx}\"\n",
    "                # Tag content for specific agents\n",
    "                agent_tag = \"energy\" if \"energy\" in file_path.lower() or \"smud\" in file_path.lower() else \"customer\"\n",
    "                \n",
    "                vectors.append({\n",
    "                    \"id\": doc_id,\n",
    "                    \"values\": vector,\n",
    "                    \"metadata\": {\n",
    "                        \"text\": chunk.page_content,\n",
    "                        \"source\": os.path.basename(file_path),\n",
    "                        \"agent\": agent_tag\n",
    "                    }\n",
    "                })\n",
    "\n",
    "                if len(vectors) >= batch_size:\n",
    "                    index.upsert(vectors=vectors)\n",
    "                    vectors = []\n",
    "                    print(f\"      Uploaded batch...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    if vectors: index.upsert(vectors=vectors)\n",
    "    print(\"‚úÖ Upload Complete!\")\n",
    "\n",
    "# UPLOAD FILES TO COLAB SIDEBAR, THEN RUN:\n",
    "# files = [\"your_file.csv\", \"your_doc.pdf\"]\n",
    "# process_files(files)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
